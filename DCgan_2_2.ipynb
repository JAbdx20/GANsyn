{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAbdx20/GANsyn/blob/main/DCgan_2_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d2f9RBmZ8DPZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Embedding, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1NLM7l79lIH"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8yJ95RNKHNx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# List of the uploaded filenames\n",
        "uploaded_files = list(uploaded.keys())\n",
        "\n",
        "# First 10 images displayed\n",
        "num_images_to_display = min(10, len(uploaded_files))\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i, filename in enumerate(uploaded_files[:num_images_to_display]):\n",
        "    img_data = uploaded[filename]\n",
        "    img = Image.open(io.BytesIO(img_data)).convert('L')\n",
        "\n",
        "    plt.subplot(1, num_images_to_display, i+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(filename)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ygw8svjr8Y_5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create data augmentation configuration\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.5, 1.5],\n",
        "    zoom_range=0.3\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LVGrv-YrbeRb"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X97N2IVZ_qw_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "img_dir = \"./\"\n",
        "image_files = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CybDxOtImfRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4069e08-18a2-434b-e6d5-f2f56240b600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n"
          ]
        }
      ],
      "source": [
        "print(len(image_files))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-QPbnS-imdFm"
      },
      "outputs": [],
      "source": [
        "# Load and augment images\n",
        "images = []\n",
        "for img_file in image_files:\n",
        "    img_path = os.path.join(img_dir, img_file)\n",
        "    img = load_img(img_path, color_mode='grayscale', target_size=(56, 56))\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    for _ in range(20):\n",
        "        augmented_img = datagen.random_transform(img_array)\n",
        "        images.append(augmented_img)\n",
        "\n",
        "# Convert to numpy array and normalize\n",
        "images = np.array(images) / 255.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "N70e1dzUvpFu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def plot_augmented_images(images, num_examples=10):\n",
        "\n",
        "    plt.figure(figsize=(20, 2))\n",
        "    for i in range(num_examples):\n",
        "        plt.subplot(1, num_examples, i+1)\n",
        "        plt.imshow(images[i].reshape(56, 56), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAM1JTj2xGbH"
      },
      "outputs": [],
      "source": [
        "plot_augmented_images(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p5SEyOJ6_v0b"
      },
      "outputs": [],
      "source": [
        "\n",
        "labels = np.zeros((len(images), 1))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9wKNBVxUfUbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc03de8a-2c1b-417c-bafd-79144641ab16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1600\n",
            "1600\n"
          ]
        }
      ],
      "source": [
        "print(len(images))\n",
        "print(len(labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AYoAJ1HIC6Id"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "BUFFER_SIZE = len(images)\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "# Convert to TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices(images)\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Conv2D, UpSampling2D, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "_k3IT5h7ktm0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6_Lls1ATEgdh"
      },
      "outputs": [],
      "source": [
        "noise_dim = 100\n",
        "\n",
        "def build_generator(noise_dim):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(128 * 14 * 14, input_dim=noise_dim))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Reshape((14, 14, 128)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size=3, padding='same'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    model.add(Conv2D(1, kernel_size=3, padding='same', activation='tanh'))  # Producing [-1, 1] due to tanh\n",
        "\n",
        "    noise = Input(shape=(noise_dim,))\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise, img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bHWhYs7qaV31"
      },
      "outputs": [],
      "source": [
        "def build_discriminator(img_shape):\n",
        "\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    model = Sequential()\n",
        "\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    img = Input(shape=img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mlWWD08Bae9k"
      },
      "outputs": [],
      "source": [
        "from keras.initializers import RandomNormal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_combined():\n",
        "    # Build and compile the discriminator\n",
        "    discriminator = build_discriminator((56, 56, 1))\n",
        "    discriminator.compile(loss=['binary_crossentropy'],\n",
        "                          optimizer=Adam(0.0001, 0.5),\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "    # Ensure the discriminator doesn't get updated during the combined model training\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    # Build the generator\n",
        "    generator = build_generator(noise_dim)\n",
        "\n",
        "    # The generator takes noise as input and generates imgs\n",
        "    z = Input(shape=(noise_dim,))\n",
        "    img = generator(z)\n",
        "\n",
        "    # The discriminator takes generated images as input and determines validity\n",
        "    validity = discriminator(img)\n",
        "\n",
        "    # Combined model\n",
        "    combined = Model(z, validity)\n",
        "    combined.compile(loss='binary_crossentropy',\n",
        "                     optimizer=Adam(learning_rate=0.0004, beta_1=0.5))\n",
        "\n",
        "    return generator, discriminator, combined\n",
        "\n",
        "generator, discriminator, combined = build_combined()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG_CldOEcOgq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 400\n",
        "batch_size = 20\n",
        "\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "noise_dim = 100\n",
        "\n",
        "# Function to display generated images\n",
        "def plot_generated_images(epoch, generator, num_examples=10, dim=(1, 10), figsize=(10, 1)):\n",
        "    noise = np.random.normal(0, 1, size=[num_examples, noise_dim])\n",
        "    generated_images = generator.predict(noise)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(num_examples):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i, :, :, 0], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'gan_generated_image_epoch_{epoch}.png')\n",
        "    plt.show()\n",
        "\n",
        "def smooth_labels(y):\n",
        "    # Randomly smooth labels\n",
        "    factor = np.random.uniform(0.7, 1.2)\n",
        "    y *= factor\n",
        "    return y\n",
        "\n",
        "# Pre-training the Discriminator\n",
        "pre_train_epochs = 10\n",
        "for epoch in range(pre_train_epochs):\n",
        "    for batch_imgs in dataset:\n",
        "        noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        valid_smooth = smooth_labels(valid)\n",
        "\n",
        "        discriminator.train_on_batch(batch_imgs, valid_smooth)\n",
        "        discriminator.train_on_batch(gen_imgs, fake)\n",
        "\n",
        "d_loss_history = []\n",
        "g_loss_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    d_losses = []\n",
        "    g_losses = []\n",
        "\n",
        "    for batch_imgs in dataset:\n",
        "        noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        valid_smooth = smooth_labels(valid)\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(batch_imgs, valid_smooth)\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train the Generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "        g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "        d_losses.append(d_loss[0])\n",
        "        g_losses.append(g_loss)\n",
        "\n",
        "    avg_d_loss = np.mean(d_losses)\n",
        "    avg_g_loss = np.mean(g_losses)\n",
        "    avg_d_loss = np.mean(d_losses)\n",
        "    avg_g_loss = np.mean(g_losses)\n",
        "\n",
        "    d_loss_history.append(avg_d_loss)\n",
        "    g_loss_history.append(avg_g_loss)\n",
        "\n",
        "    print(f\"{epoch}/{epochs} [D avg loss: {avg_d_loss} | D accuracy: {100*d_loss[1]}] [G avg loss: {avg_g_loss}]\")\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        plot_generated_images(epoch, generator)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt1PQZ4KBEln"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_generated_images(generated_imgs, sampled_labels, num_examples=10):\n",
        "    plt.figure(figsize=(10, num_examples//2))\n",
        "\n",
        "    for i in range(num_examples):\n",
        "        plt.subplot(num_examples//10, 10, i+1)\n",
        "        plt.imshow(gen_imgs[i, :, :, 0], interpolation='nearest', cmap='gray_r')\n",
        "        plt.title(f\"Label: {sampled_labels[i][0]}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz1EsLzsRgf4"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_examples = 10\n",
        "\n",
        "# Random noise as input for the generator\n",
        "noise = np.random.normal(0, 1, size=[num_examples, noise_dim])\n",
        "\n",
        "# to generate images\n",
        "generated_images = generator.predict(noise)\n",
        "\n",
        "# Visualization function\n",
        "def visualize_generated_images(generated_imgs, num_examples=10):\n",
        "    plt.figure(figsize=(15, num_examples // 2))\n",
        "\n",
        "    for i in range(num_examples):\n",
        "        plt.subplot(num_examples // 5, 5, i + 1)\n",
        "        plt.imshow(generated_imgs[i, :, :, 0], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call function to visualize the images\n",
        "visualize_generated_images(generated_images)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Discriminator and Generator loss\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.plot(d_loss_history, label=\"Discriminator Loss\")\n",
        "plt.plot(g_loss_history, label=\"Generator Loss\")\n",
        "\n",
        "plt.title(\"GAN Loss Evolution\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UiFwF6aeAbiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference\n",
        "''' The code scripted were adapted from following source\n",
        " URL: https://github.com/keras-team/keras\n",
        " URL: https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/dcgan/dcgan.py\n",
        " URL: https://github.com/nicknochnack/GANBasics/blob/main/FashionGAN-Tutorial.ipynb\n",
        " URL: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
        " URL: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        " URL: https://colab.research.google.com/drive/10rnPKb4Hnr4pN-hihZfMK2QLrsJEgJm0?usp=sharing '''"
      ],
      "metadata": {
        "id": "kNk9TamHcWd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wAlBjUbgeWB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdWfegzFnHqGjCiTj40k34",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}